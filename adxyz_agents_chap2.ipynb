{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGENT #\n",
    "\n",
    "An agent, as defined in 2.1 is anything that can perceive its <b>environment</b> through sensors, and act upon that environment through actuators based on its <b>agent program</b>. This can be a dog, robot, or even you. As long as you can perceive the environment and act on it, you are an agent. This notebook will explain how to implement a simple agent, create an environment, and create a program that helps the agent act on the environment based on its percepts.\n",
    "\n",
    "Before moving on, review the </b>Agent</b> and </b>Environment</b> classes in <b>[agents.py](https://github.com/aimacode/aima-python/blob/master/agents.py)</b>.\n",
    "\n",
    "Let's begin by importing all the functions from the agents.py module and creating our first agent - a blind dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from agents import *\n",
    "\n",
    "#class BlindDog(Agent):\n",
    "#    def eat(self, thing):\n",
    "#        print(\"Dog: Ate food at {}.\".format(self.location))\n",
    "#            \n",
    "#    def drink(self, thing):\n",
    "#        print(\"Dog: Drank water at {}.\".format( self.location))\n",
    "#\n",
    "#dog = BlindDog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have just done is create a dog who can only feel what's in his location (since he's blind), and can eat or drink. Let's see if he's alive..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(dog.alive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--- \n",
    "![Cool dog](https://gifgun.files.wordpress.com/2015/07/wpid-wp-1435860392895.gif) This is our dog. How cool is he? Well, he's hungry and needs to go search for food. For him to do this, we need to give him a program. But before that, let's create a park for our dog to play in.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENVIRONMENT #\n",
    "\n",
    "A park is an example of an environment because our dog can perceive and act upon it. The <b>Environment</b> class in agents.py is an abstract class, so we will have to create our own subclass from it before we can use it. The abstract class must contain the following methods:\n",
    "\n",
    "<li><b>percept(self, agent)</b> - returns what the agent perceives</li>\n",
    "<li><b>execute_action(self, agent, action)</b> - changes the state of the environment based on what the agent does.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#class Food(Thing):\n",
    "#    pass\n",
    "\n",
    "#class Water(Thing):\n",
    "#    pass\n",
    "\n",
    "#class Park(Environment):\n",
    "#    def percept(self, agent):\n",
    "#        '''prints & return a list of things that are in our agent's location'''\n",
    "#        things = self.list_things_at(agent.location)\n",
    "#        print(things)\n",
    "#        return things\n",
    "    \n",
    "#    def execute_action(self, agent, action):\n",
    "#        '''changes the state of the environment based on what the agent does.'''\n",
    "#        if action == \"move down\":\n",
    "#            agent.movedown()\n",
    "#        elif action == \"eat\":\n",
    "#            items = self.list_things_at(agent.location, tclass=Food)\n",
    "#            if len(items) != 0:\n",
    "#                if agent.eat(items[0]): #Have the dog pick eat the first item\n",
    "#                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "#        elif action == \"drink\":\n",
    "#            items = self.list_things_at(agent.location, tclass=Water)\n",
    "#            if len(items) != 0:\n",
    "#                if agent.drink(items[0]): #Have the dog drink the first item\n",
    "#                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "                    \n",
    "#    def is_done(self):\n",
    "#        '''By default, we're done when we can't find a live agent, \n",
    "#        but to prevent killing our cute dog, we will or it with when there is no more food or water'''\n",
    "#        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "#        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "#        return dead_agents or no_edibles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wumpus Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from ipythonblocks import BlockGrid\n",
    "#from agents import *\n",
    "\n",
    "#color = {\"Breeze\": (225, 225, 225),\n",
    "#        \"Pit\": (0,0,0),\n",
    "#        \"Gold\": (253, 208, 23),\n",
    "#        \"Glitter\": (253, 208, 23),\n",
    "#        \"Wumpus\": (43, 27, 23),\n",
    "#        \"Stench\": (128, 128, 128),\n",
    "#        \"Explorer\": (0, 0, 255),\n",
    "#        \"Wall\": (44, 53, 57)\n",
    "#        }\n",
    "\n",
    "#def program(percepts):\n",
    "#    '''Returns an action based on it's percepts'''\n",
    "#    print(percepts)\n",
    "#    return input()\n",
    "\n",
    "#w = WumpusEnvironment(program, 7, 7)         \n",
    "#grid = BlockGrid(w.width, w.height, fill=(123, 234, 123))\n",
    "\n",
    "#def draw_grid(world):\n",
    "#    global grid\n",
    "#    grid[:] = (123, 234, 123)\n",
    "#    for x in range(0, len(world)):\n",
    "#        for y in range(0, len(world[x])):\n",
    "#            if len(world[x][y]):\n",
    "#                grid[y, x] = color[world[x][y][-1].__class__.__name__]\n",
    "\n",
    "#def step():\n",
    "#    global grid, w\n",
    "#    draw_grid(w.get_world())\n",
    "#    grid.show()\n",
    "#    w.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PROGRAM #\n",
    "Now that we have a <b>Park</b> Class, we need to implement a <b>program</b> module for our dog. A program controls how the dog acts upon it's environment. Our program will be very simple, and is shown in the table below.\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><b>Percept:</b> </td>\n",
    "        <td>Feel Food </td>\n",
    "        <td>Feel Water</td>\n",
    "        <td>Feel Nothing</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "       <td><b>Action:</b> </td>\n",
    "       <td>eat</td>\n",
    "       <td>drink</td>\n",
    "       <td>move up</td>\n",
    "   </tr>\n",
    "        \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#class BlindDog(Agent):\n",
    "#    location = 1\n",
    "    \n",
    "#    def movedown(self):\n",
    "#        self.location += 1\n",
    "        \n",
    "#    def eat(self, thing):\n",
    "#        '''returns True upon success or False otherwise'''\n",
    "#        if isinstance(thing, Food):\n",
    "#            print(\"Dog: Ate food at {}.\".format(self.location))\n",
    "#            return True\n",
    "#        return False\n",
    "    \n",
    "#    def drink(self, thing):\n",
    "#        ''' returns True upon success or False otherwise'''\n",
    "#        if isinstance(thing, Water):\n",
    "#            print(\"Dog: Drank water at {}.\".format(self.location))\n",
    "#            return True\n",
    "#        return False\n",
    "        \n",
    "#def program(percepts):\n",
    "#    '''Returns an action based on it's percepts'''\n",
    "#    for p in percepts:\n",
    "#        if isinstance(p, Food):\n",
    "#            return 'eat'\n",
    "#        elif isinstance(p, Water):\n",
    "#            return 'drink'\n",
    "#    return 'move down'               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#park = Park()\n",
    "#dog = BlindDog(program)\n",
    "#dogfood = Food()\n",
    "#water = Water()\n",
    "#park.add_thing(dog, 0)\n",
    "#park.add_thing(dogfood, 5)\n",
    "#park.add_thing(water, 7)\n",
    "\n",
    "#park.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's how easy it is to implement an agent, its program, and environment. But that was a very simple case. What if our environment was 2-Dimentional instead of 1? And what if we had multiple agents?\n",
    "\n",
    "To make our Park 2D, we will need to make it a subclass of <b>XYEnvironment</b> instead of Environment. Also, let's add a person to play fetch with the dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class Park(XYEnvironment):\n",
    "#    def percept(self, agent):\n",
    "#        '''prints & return a list of things that are in our agent's location'''\n",
    "#        things = self.list_things_at(agent.location)\n",
    "#        print(things)\n",
    "#        return things\n",
    "    \n",
    "#    def execute_action(self, agent, action):\n",
    "#        '''changes the state of the environment based on what the agent does.'''\n",
    "#        if action == \"move down\":\n",
    "#            agent.movedown()\n",
    "#        elif action == \"eat\":\n",
    "#            items = self.list_things_at(agent.location, tclass=Food)\n",
    "#            if len(items) != 0:\n",
    "#                if agent.eat(items[0]): #Have the dog pick eat the first item\n",
    "#                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "#        elif action == \"drink\":\n",
    "#            items = self.list_things_at(agent.location, tclass=Water)\n",
    "#            if len(items) != 0:\n",
    "#                if agent.drink(items[0]): #Have the dog drink the first item\n",
    "#                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "                    \n",
    "#    def is_done(self):\n",
    "#        '''By default, we're done when we can't find a live agent, \n",
    "#        but to prevent killing our cute dog, we will or it with when there is no more food or water'''\n",
    "#        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "#        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "#        return dead_agents or no_edibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.8) Implement a performance-measuring environment simulator for the vacuum-cleaner world depicted in Figure 2.2 and specified on page 38.  Your implementation should be modular so that the sensors, actuators, and enviroment characteristics (size, shape, dirt placement, etc.) can be changed easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent Name:  Vacuum Robot Agent\n",
    "-------------------------------\n",
    "*Performance Measure:*  +1 point for each clean square at each time step, for 1000 time steps\n",
    "\n",
    "*Environment:*  Two squares at positions (0,0) and (1,0).  The squares can either be dirty or clean.  The agent cannot go outside those two positions.\n",
    "\n",
    "*Actuators:*  The actuators for the agent consist of the ability to move between the squares and the ability to suck up dirt.\n",
    "\n",
    "*Sensors:*  The sensors allow for the agent to know current location and also whether there is dirt or not at the square the currently occupy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agents import *\n",
    "\n",
    "# Define the dirt clump class\n",
    "class DirtClump(Thing):\n",
    "    pass\n",
    "\n",
    "#Define the environment class\n",
    "class adxyz_VacuumEnvironment(XYEnvironment):\n",
    "\n",
    "# Need to override the percept method \n",
    "    def percept(self, agent):\n",
    "        '''By default, agent perceives things within a default radius.'''\n",
    "        print (\"In override percept.\")\n",
    "        print (\"Agent ID = \", agent)\n",
    "        print (\"Agent location = \", agent.location)\n",
    "        print (\"Agent performance = \", agent.performance)\n",
    "        print (\"Self = \", self)\n",
    "        print (\"Self.things = \", self.things)\n",
    "        for iThing in range(len(self.things)):\n",
    "            if self.things[iThing].location==agent.location:  #check location\n",
    "                if self.things[iThing] != agent:  # Don't return agent information\n",
    "                    if (isinstance(self.things[iThing], DirtClump)):\n",
    "                        print (\"A thing which is not agent, but dirt clump = \", self.things[iThing] )\n",
    "                        print (\"Location = \", self.things[iThing].location)\n",
    "                        return \"DirtClump\"\n",
    "                    \n",
    "        return \"CleanSquare\"  #Default, if we don't find a dirt clump.\n",
    "                \n",
    "# Need to override the action method (and update performance measure.)\n",
    "###    def execute_action(self, agent, action):\n",
    "###        if action==\"Suck\":\n",
    "###           print(\"Action-Suck\")\n",
    "###\n",
    "#### Remember to remove the dirt clod at this location.\n",
    "###\n",
    "###        elif action==\"MoveRight\":\n",
    "###           print(\"Action-MoveRight\")\n",
    "###        elif action==\"MoveLeft\":\n",
    "###           print(\"Action-MoveLeft\")\n",
    "###        else:\n",
    "###           print(\"Action-None\")\n",
    "###\n",
    "### Count up number of clean squares (indirectly)\n",
    "### and add that to the agent peformance score\n",
    "###\n",
    "###        dirtCount=0\n",
    "###        for iThings in range(len(self.things)):\n",
    "###           if isInstance(self.things[iThings], DirtClump):\n",
    "###              dirtCount = dirtCount+1\n",
    "###\n",
    "###        cleanSquareCount = self.totalSquareCount-dirtCount \n",
    "###        agent.performance=agent.performance + 2*cleanSquareCount\n",
    "###        return\n",
    "###\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.9) Implement a simple reflex agent for the vacuum environment in Exercise 2.8.  Run the environment with this agent for all possible initial dirt configurations and agent locations.  Record the performance score for each consideration and the overall average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# The program for the simple reflex agent is:\n",
    "# \n",
    "# Percept:         Action:\n",
    "# --------         -------\n",
    "# [(0,0),Clean] -> Right\n",
    "# [(0,0),Dirty] -> Suck\n",
    "# [(1,0),Clean] -> Left\n",
    "# [(1,0),Dirty] -> Suck\n",
    "#\n",
    "\n",
    "# Instantiate a simple reflex vacuum agent\n",
    "class adxyz_SimpleReflexAgentVacuum(Agent):\n",
    "    def program(percept):\n",
    "        print(\"Agent-Percept = \", percept)\n",
    "###        if percept==\"Dirt\":\n",
    "###            return \"Suck.\"\n",
    "###        else:\n",
    "        return \"Do Nothing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0)]\n"
     ]
    }
   ],
   "source": [
    "# Define the initial dirt configurations\n",
    "initDirt=[]\n",
    "##initDirt.append([])             # neither location dirty - format(X,Y)-locations:A=(0,0), B=(1,0)\n",
    "##initDirt.append([(0,0)])        # square A dirty, square B clean\n",
    "initDirt.append([(1,0)])        # square A clean, square B dirty\n",
    "##initDirt.append([(0,0),(1,0)])  # sqaure A dirty, square B dirty\n",
    "\n",
    "print(initDirt[0])\n",
    "##print(initDirt[1])\n",
    "##print(initDirt[2])\n",
    "##print(initDirt[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer loop:\n",
      "len of initDirt =  1\n",
      "iSimDirtPlacement - outer loop =  0\n",
      "\n",
      "inner loop:\n",
      "iSimDirtPlacement - inner loop =  0\n",
      "iPlace =  0\n",
      "1\n",
      "[(1, 0)]\n",
      "myDirtClumpList =  [<DirtClump>]\n",
      "currInitDirtLocation = (1, 0)\n",
      "\n",
      "Environment:\n",
      "[(<DirtClump>, 0), (<adxyz_SimpleReflexAgentVacuum>, 0)]\n",
      "\n",
      "In override percept.\n",
      "Agent ID =  <adxyz_SimpleReflexAgentVacuum>\n",
      "Agent location =  (1, 0)\n",
      "Agent performance =  0\n",
      "Self =  <__main__.adxyz_VacuumEnvironment object at 0x104a809b0>\n",
      "Self.things =  [<DirtClump>, <adxyz_SimpleReflexAgentVacuum>]\n",
      "A thing which is not agent, but dirt clump =  <DirtClump>\n",
      "Location =  (1, 0)\n",
      "Percept=DirtClump; action? None\n"
     ]
    }
   ],
   "source": [
    "# Create a loop over environments to run simulation\n",
    "\n",
    "# Loop over agent placements\n",
    "##for iSimAgentPlacement in range(len(initAgent)):\n",
    "for iSimAgentPlacement in range(1):\n",
    "# Loop over dirt placements\n",
    "    for iSimDirtPlacement in range(len(initDirt)):\n",
    "        print(\"outer loop:\")\n",
    "        print(\"len of initDirt = \", len(initDirt))\n",
    "        print (\"iSimDirtPlacement - outer loop = \" , iSimDirtPlacement)\n",
    "        \n",
    "        myVacEnv = adxyz_VacuumEnvironment() #Create a new environment for each dirt/agent setup\n",
    "        myDirtClumpList = []\n",
    "\n",
    "        for iPlace in range(len(initDirt[iSimDirtPlacement])):\n",
    "            print(\"\")\n",
    "            print(\"inner loop:\")\n",
    "            print (\"iSimDirtPlacement - inner loop = \" , iSimDirtPlacement)\n",
    "            print (\"iPlace = \" , iPlace)\n",
    "            print(len(initDirt[iSimDirtPlacement]))\n",
    "            print(initDirt[iSimDirtPlacement])\n",
    "            myDirtClumpList.append(DirtClump())\n",
    "            print(\"myDirtClumpList = \", myDirtClumpList)\n",
    "            currInitDirtLocation = initDirt[iSimDirtPlacement][iPlace]\n",
    "            print(\"currInitDirtLocation =\", currInitDirtLocation)\n",
    "            myVacEnv.add_thing(myDirtClumpList[iPlace],location=currInitDirtLocation)\n",
    "            \n",
    "\n",
    "#\n",
    "# Now place the agent.\n",
    "#\n",
    "        myAgent=adxyz_SimpleReflexAgentVacuum()\n",
    "        myVacEnv.add_thing(myAgent,location=(1,0))\n",
    "        print(\"\")\n",
    "        print(\"Environment:\")\n",
    "        print(myVacEnv.things_near(location=(0,0)))\n",
    "        print(\"\")\n",
    "        \n",
    "#\n",
    "# Now step the environment clock\n",
    "#\n",
    "\n",
    "        myVacEnv.step()\n",
    "    \n",
    "#\n",
    "# End of script\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
