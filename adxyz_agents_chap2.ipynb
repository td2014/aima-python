{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGENT #\n",
    "\n",
    "An agent, as defined in 2.1 is anything that can perceive its <b>environment</b> through sensors, and act upon that environment through actuators based on its <b>agent program</b>. This can be a dog, robot, or even you. As long as you can perceive the environment and act on it, you are an agent. This notebook will explain how to implement a simple agent, create an environment, and create a program that helps the agent act on the environment based on its percepts.\n",
    "\n",
    "Before moving on, review the </b>Agent</b> and </b>Environment</b> classes in <b>[agents.py](https://github.com/aimacode/aima-python/blob/master/agents.py)</b>.\n",
    "\n",
    "Let's begin by importing all the functions from the agents.py module and creating our first agent - a blind dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from agents import *\n",
    "\n",
    "#class BlindDog(Agent):\n",
    "#    def eat(self, thing):\n",
    "#        print(\"Dog: Ate food at {}.\".format(self.location))\n",
    "#            \n",
    "#    def drink(self, thing):\n",
    "#        print(\"Dog: Drank water at {}.\".format( self.location))\n",
    "#\n",
    "#dog = BlindDog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have just done is create a dog who can only feel what's in his location (since he's blind), and can eat or drink. Let's see if he's alive..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(dog.alive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--- \n",
    "![Cool dog](https://gifgun.files.wordpress.com/2015/07/wpid-wp-1435860392895.gif) This is our dog. How cool is he? Well, he's hungry and needs to go search for food. For him to do this, we need to give him a program. But before that, let's create a park for our dog to play in.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENVIRONMENT #\n",
    "\n",
    "A park is an example of an environment because our dog can perceive and act upon it. The <b>Environment</b> class in agents.py is an abstract class, so we will have to create our own subclass from it before we can use it. The abstract class must contain the following methods:\n",
    "\n",
    "<li><b>percept(self, agent)</b> - returns what the agent perceives</li>\n",
    "<li><b>execute_action(self, agent, action)</b> - changes the state of the environment based on what the agent does.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#class Food(Thing):\n",
    "#    pass\n",
    "\n",
    "#class Water(Thing):\n",
    "#    pass\n",
    "\n",
    "#class Park(Environment):\n",
    "#    def percept(self, agent):\n",
    "#        '''prints & return a list of things that are in our agent's location'''\n",
    "#        things = self.list_things_at(agent.location)\n",
    "#        print(things)\n",
    "#        return things\n",
    "    \n",
    "#    def execute_action(self, agent, action):\n",
    "#        '''changes the state of the environment based on what the agent does.'''\n",
    "#        if action == \"move down\":\n",
    "#            agent.movedown()\n",
    "#        elif action == \"eat\":\n",
    "#            items = self.list_things_at(agent.location, tclass=Food)\n",
    "#            if len(items) != 0:\n",
    "#                if agent.eat(items[0]): #Have the dog pick eat the first item\n",
    "#                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "#        elif action == \"drink\":\n",
    "#            items = self.list_things_at(agent.location, tclass=Water)\n",
    "#            if len(items) != 0:\n",
    "#                if agent.drink(items[0]): #Have the dog drink the first item\n",
    "#                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "                    \n",
    "#    def is_done(self):\n",
    "#        '''By default, we're done when we can't find a live agent, \n",
    "#        but to prevent killing our cute dog, we will or it with when there is no more food or water'''\n",
    "#        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "#        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "#        return dead_agents or no_edibles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wumpus Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from ipythonblocks import BlockGrid\n",
    "#from agents import *\n",
    "\n",
    "#color = {\"Breeze\": (225, 225, 225),\n",
    "#        \"Pit\": (0,0,0),\n",
    "#        \"Gold\": (253, 208, 23),\n",
    "#        \"Glitter\": (253, 208, 23),\n",
    "#        \"Wumpus\": (43, 27, 23),\n",
    "#        \"Stench\": (128, 128, 128),\n",
    "#        \"Explorer\": (0, 0, 255),\n",
    "#        \"Wall\": (44, 53, 57)\n",
    "#        }\n",
    "\n",
    "#def program(percepts):\n",
    "#    '''Returns an action based on it's percepts'''\n",
    "#    print(percepts)\n",
    "#    return input()\n",
    "\n",
    "#w = WumpusEnvironment(program, 7, 7)         \n",
    "#grid = BlockGrid(w.width, w.height, fill=(123, 234, 123))\n",
    "\n",
    "#def draw_grid(world):\n",
    "#    global grid\n",
    "#    grid[:] = (123, 234, 123)\n",
    "#    for x in range(0, len(world)):\n",
    "#        for y in range(0, len(world[x])):\n",
    "#            if len(world[x][y]):\n",
    "#                grid[y, x] = color[world[x][y][-1].__class__.__name__]\n",
    "\n",
    "#def step():\n",
    "#    global grid, w\n",
    "#    draw_grid(w.get_world())\n",
    "#    grid.show()\n",
    "#    w.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PROGRAM #\n",
    "Now that we have a <b>Park</b> Class, we need to implement a <b>program</b> module for our dog. A program controls how the dog acts upon it's environment. Our program will be very simple, and is shown in the table below.\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><b>Percept:</b> </td>\n",
    "        <td>Feel Food </td>\n",
    "        <td>Feel Water</td>\n",
    "        <td>Feel Nothing</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "       <td><b>Action:</b> </td>\n",
    "       <td>eat</td>\n",
    "       <td>drink</td>\n",
    "       <td>move up</td>\n",
    "   </tr>\n",
    "        \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#class BlindDog(Agent):\n",
    "#    location = 1\n",
    "    \n",
    "#    def movedown(self):\n",
    "#        self.location += 1\n",
    "        \n",
    "#    def eat(self, thing):\n",
    "#        '''returns True upon success or False otherwise'''\n",
    "#        if isinstance(thing, Food):\n",
    "#            print(\"Dog: Ate food at {}.\".format(self.location))\n",
    "#            return True\n",
    "#        return False\n",
    "    \n",
    "#    def drink(self, thing):\n",
    "#        ''' returns True upon success or False otherwise'''\n",
    "#        if isinstance(thing, Water):\n",
    "#            print(\"Dog: Drank water at {}.\".format(self.location))\n",
    "#            return True\n",
    "#        return False\n",
    "        \n",
    "#def program(percepts):\n",
    "#    '''Returns an action based on it's percepts'''\n",
    "#    for p in percepts:\n",
    "#        if isinstance(p, Food):\n",
    "#            return 'eat'\n",
    "#        elif isinstance(p, Water):\n",
    "#            return 'drink'\n",
    "#    return 'move down'               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#park = Park()\n",
    "#dog = BlindDog(program)\n",
    "#dogfood = Food()\n",
    "#water = Water()\n",
    "#park.add_thing(dog, 0)\n",
    "#park.add_thing(dogfood, 5)\n",
    "#park.add_thing(water, 7)\n",
    "\n",
    "#park.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's how easy it is to implement an agent, its program, and environment. But that was a very simple case. What if our environment was 2-Dimentional instead of 1? And what if we had multiple agents?\n",
    "\n",
    "To make our Park 2D, we will need to make it a subclass of <b>XYEnvironment</b> instead of Environment. Also, let's add a person to play fetch with the dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class Park(XYEnvironment):\n",
    "#    def percept(self, agent):\n",
    "#        '''prints & return a list of things that are in our agent's location'''\n",
    "#        things = self.list_things_at(agent.location)\n",
    "#        print(things)\n",
    "#        return things\n",
    "    \n",
    "#    def execute_action(self, agent, action):\n",
    "#        '''changes the state of the environment based on what the agent does.'''\n",
    "#        if action == \"move down\":\n",
    "#            agent.movedown()\n",
    "#        elif action == \"eat\":\n",
    "#            items = self.list_things_at(agent.location, tclass=Food)\n",
    "#            if len(items) != 0:\n",
    "#                if agent.eat(items[0]): #Have the dog pick eat the first item\n",
    "#                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "#        elif action == \"drink\":\n",
    "#            items = self.list_things_at(agent.location, tclass=Water)\n",
    "#            if len(items) != 0:\n",
    "#                if agent.drink(items[0]): #Have the dog drink the first item\n",
    "#                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "                    \n",
    "#    def is_done(self):\n",
    "#        '''By default, we're done when we can't find a live agent, \n",
    "#        but to prevent killing our cute dog, we will or it with when there is no more food or water'''\n",
    "#        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "#        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "#        return dead_agents or no_edibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.8) Implement a performance-measuring environment simulator for the vacuum-cleaner world depicted in Figure 2.2 and specified on page 38.  Your implementation should be modular so that the sensors, actuators, and enviroment characteristics (size, shape, dirt placement, etc.) can be changed easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent Name:  Vacuum Robot Agent\n",
    "-------------------------------\n",
    "*Performance Measure:*  +1 point for each clean square at each time step, for 1000 time steps\n",
    "\n",
    "*Environment:*  Two squares at positions (0,0) and (1,0).  The squares can either be dirty or clean.  The agent cannot go outside those two positions.\n",
    "\n",
    "*Actuators:*  The actuators for the agent consist of the ability to move between the squares and the ability to suck up dirt.\n",
    "\n",
    "*Sensors:*  The sensors allow for the agent to know current location and also whether there is dirt or not at the square the currently occupy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agents import *\n",
    "\n",
    "# Define the dirt clump class\n",
    "class DirtClump(Thing):\n",
    "    pass\n",
    "\n",
    "#Define the environment class\n",
    "class adxyz_VacuumEnvironment(XYEnvironment):\n",
    "\n",
    "# Need to override the percept method \n",
    "    def percept(self, agent):\n",
    "        print ()\n",
    "        print (\"In adxyz_VacuumEnvironment - percept override:\")\n",
    "        print (\"Self = \", self)\n",
    "        print (\"Self.things = \", self.things)\n",
    "        print (\"Agent ID = \", agent)\n",
    "        print (\"Agent location = \", agent.location)\n",
    "        print (\"Agent performance = \", agent.performance)\n",
    "        \n",
    "        for iThing in range(len(self.things)):\n",
    "            if self.things[iThing].location==agent.location:  #check location\n",
    "                if self.things[iThing] != agent:  # Don't return agent information\n",
    "                    if (isinstance(self.things[iThing], DirtClump)):\n",
    "                        print (\"A thing which is not agent, but a dirt clump = \", self.things[iThing] )\n",
    "                        print (\"Location = \", self.things[iThing].location)\n",
    "                        return agent.location, \"DirtClump\"\n",
    "                    \n",
    "        return agent.location, \"CleanSquare\"  #Default, if we don't find a dirt clump.\n",
    "                \n",
    "# Need to override the action method (and update performance measure.)\n",
    "    def execute_action(self, agent, action):\n",
    "        print ()\n",
    "        print (\"In adxyz_VacuumEnvironment - execute_action override:\")\n",
    "        print(\"self = \", self)\n",
    "        print(\"agent = \", agent)\n",
    "        print(\"current agent action = \", action)\n",
    "        print()\n",
    "        if action==\"Suck\":\n",
    "            print(\"Action-Suck\")\n",
    "            print(\"Need to remove dirt clump at correct location\")\n",
    "            deleteList = []\n",
    "            for iThing in range(len(self.things)):\n",
    "                if self.things[iThing].location==agent.location:  #check location\n",
    "                    if (isinstance(self.things[iThing], DirtClump)):  # Only clean dirt\n",
    "                        print (\"A thing which is not agent, but a dirt clump = \", self.things[iThing])\n",
    "                        print (\"Location of dirt clod = \", self.things[iThing].location)\n",
    "                        self.delete_thing(self.things[iThing])\n",
    "                        break  # can only do one deletion per action.\n",
    "                                   \n",
    "        elif action==\"MoveRight\":\n",
    "            print(\"Action-MoveRight\")\n",
    "            print(\"agent direction before MoveRight = \", agent.direction)\n",
    "            print(\"agent location before MoveRight = \", agent.location)\n",
    "            agent.bump = False\n",
    "            agent.direction = agent.direction + Direction.R\n",
    "            agent.direction = agent.direction + Direction.R\n",
    "            agent.bump = self.move_to(agent, agent.direction.move_forward(agent.location))\n",
    "            print(\"agent direction after MoveRight = \", agent.direction)\n",
    "            print(\"agent location after MoveRight = \", agent.location)\n",
    "            print()\n",
    "            \n",
    "        elif action==\"MoveLeft\":\n",
    "            print(\"Action-MoveLeft\")\n",
    "            print(\"agent direction before MoveLeft = \", agent.direction)\n",
    "            print(\"agent location before MoveLeft = \", agent.location)\n",
    "            agent.bump = False\n",
    "            agent.direction = agent.direction + Direction.L\n",
    "            agent.direction = agent.direction + Direction.L\n",
    "            agent.bump = self.move_to(agent, agent.direction.move_forward(agent.location))\n",
    "            print(\"agent direction after MoveLeft = \", agent.direction)\n",
    "            print(\"agent location after MoveLeft = \", agent.location)\n",
    "            print()\n",
    "            \n",
    "        elif action==\"DoNothing\":\n",
    "            print(\"Action-DoNothing\")\n",
    "            \n",
    "        else:\n",
    "            print(\"Action-Not Understood\")  #probably error.  Don't go to score section.\n",
    "            return\n",
    "                \n",
    "###\n",
    "### Count up number of clean squares (indirectly)\n",
    "### and add that to the agent peformance score\n",
    "###\n",
    "        print(\"Before dirt count update, agent.performance = \", agent.performance)\n",
    "        dirtCount=0\n",
    "        for iThings in range(len(self.things)):\n",
    "            if isinstance(self.things[iThings], DirtClump):\n",
    "                dirtCount = dirtCount+1\n",
    "\n",
    "        cleanSquareCount = self.width*self.height-dirtCount \n",
    "        agent.performance=agent.performance + cleanSquareCount\n",
    "        print(\"After execute_action, agent.performance = \", agent.performance)\n",
    "        return    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.9) Implement a simple reflex agent for the vacuum environment in Exercise 2.8.  Run the environment with this agent for all possible initial dirt configurations and agent locations.  Record the performance score for each consideration and the overall average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# The program for the simple reflex agent is:\n",
    "# \n",
    "# Percept:         Action:\n",
    "# --------         -------\n",
    "# [(0,0),Clean] -> Right\n",
    "# [(0,0),Dirty] -> Suck\n",
    "# [(1,0),Clean] -> Left\n",
    "# [(1,0),Dirty] -> Suck\n",
    "#\n",
    "\n",
    "def SimpleReflexClean(percept):\n",
    "     \n",
    "    if percept[0] == (0,0) and percept[1]==\"DirtClump\":\n",
    "        return \"Suck\"\n",
    "    elif percept[0] == (1,0) and percept[1]==\"DirtClump\":\n",
    "        return \"Suck\"\n",
    "    elif percept[0] == (0,0) and percept[1]==\"CleanSquare\":\n",
    "        return \"MoveRight\"\n",
    "    elif percept[0] == (1,0) and percept[1]==\"CleanSquare\":\n",
    "        return \"MoveLeft\"\n",
    "    else:\n",
    "        return \"DoNothing\" # Not sure how you would get here, but DoNothing to be safe.\n",
    "\n",
    "# Instantiate a simple reflex vacuum agent\n",
    "class adxyz_SimpleReflexAgentVacuum(Agent):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 0)]\n"
     ]
    }
   ],
   "source": [
    "# Define the initial dirt configurations\n",
    "initDirt=[]\n",
    "initDirt.append([])             # neither location dirty - format(X,Y)-locations:A=(0,0), B=(1,0)\n",
    "##initDirt.append([(0,0)])        # square A dirty, square B clean\n",
    "##initDirt.append([(1,0)])        # square A clean, square B dirty\n",
    "###initDirt.append([(0,0),(1,0)])  # square A dirty, square B dirty\n",
    "\n",
    "print(initDirt[0])\n",
    "##print(initDirt[1])\n",
    "##print(initDirt[2])\n",
    "##print(initDirt[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation: iSimAgentPlacement =  0\n",
      "Simulation: iSimDirtPlacement =  0\n",
      "Simulation: iPlace =  0\n",
      "Simulation: currInitDirtLocation =  (0, 0)\n",
      "Simulation: iPlace =  1\n",
      "Simulation: currInitDirtLocation =  (1, 0)\n",
      "\n",
      "Environment:\n",
      "<DirtClump> (0, 0)\n",
      "<DirtClump> (1, 0)\n",
      "<adxyz_SimpleReflexAgentVacuum> (1, 0)\n",
      "\n",
      "\n",
      "<---START--->\n",
      "Simulation: step = 0\n",
      "\n",
      "In adxyz_VacuumEnvironment - percept override:\n",
      "Self =  <__main__.adxyz_VacuumEnvironment object at 0x105498128>\n",
      "Self.things =  [<DirtClump>, <DirtClump>, <adxyz_SimpleReflexAgentVacuum>]\n",
      "Agent ID =  <adxyz_SimpleReflexAgentVacuum>\n",
      "Agent location =  (1, 0)\n",
      "Agent performance =  0\n",
      "A thing which is not agent, but a dirt clump =  <DirtClump>\n",
      "Location =  (1, 0)\n",
      "\n",
      "In adxyz_VacuumEnvironment - execute_action override:\n",
      "self =  <__main__.adxyz_VacuumEnvironment object at 0x105498128>\n",
      "agent =  <adxyz_SimpleReflexAgentVacuum>\n",
      "current agent action =  Suck\n",
      "\n",
      "Action-Suck\n",
      "Need to remove dirt clump at correct location\n",
      "A thing which is not agent, but a dirt clump =  <DirtClump>\n",
      "Location of dirt clod =  (1, 0)\n",
      "Before dirt count update, agent.performance =  0\n",
      "After execute_action, agent.performance =  1\n",
      "---END---\n",
      "---------\n",
      "\n",
      "\n",
      "<---START--->\n",
      "Simulation: step = 1\n",
      "\n",
      "In adxyz_VacuumEnvironment - percept override:\n",
      "Self =  <__main__.adxyz_VacuumEnvironment object at 0x105498128>\n",
      "Self.things =  [<DirtClump>, <adxyz_SimpleReflexAgentVacuum>]\n",
      "Agent ID =  <adxyz_SimpleReflexAgentVacuum>\n",
      "Agent location =  (1, 0)\n",
      "Agent performance =  1\n",
      "\n",
      "In adxyz_VacuumEnvironment - execute_action override:\n",
      "self =  <__main__.adxyz_VacuumEnvironment object at 0x105498128>\n",
      "agent =  <adxyz_SimpleReflexAgentVacuum>\n",
      "current agent action =  MoveLeft\n",
      "\n",
      "Action-MoveLeft\n",
      "agent direction before MoveLeft =  <agents.Direction object at 0x105498390>\n",
      "agent location before MoveLeft =  (1, 0)\n",
      "agent direction after MoveLeft =  <agents.Direction object at 0x105498048>\n",
      "agent location after MoveLeft =  (0, 0)\n",
      "\n",
      "Before dirt count update, agent.performance =  1\n",
      "After execute_action, agent.performance =  2\n",
      "---END---\n",
      "---------\n",
      "\n",
      "\n",
      "<---START--->\n",
      "Simulation: step = 2\n",
      "\n",
      "In adxyz_VacuumEnvironment - percept override:\n",
      "Self =  <__main__.adxyz_VacuumEnvironment object at 0x105498128>\n",
      "Self.things =  [<DirtClump>, <adxyz_SimpleReflexAgentVacuum>]\n",
      "Agent ID =  <adxyz_SimpleReflexAgentVacuum>\n",
      "Agent location =  (0, 0)\n",
      "Agent performance =  2\n",
      "A thing which is not agent, but a dirt clump =  <DirtClump>\n",
      "Location =  (0, 0)\n",
      "\n",
      "In adxyz_VacuumEnvironment - execute_action override:\n",
      "self =  <__main__.adxyz_VacuumEnvironment object at 0x105498128>\n",
      "agent =  <adxyz_SimpleReflexAgentVacuum>\n",
      "current agent action =  Suck\n",
      "\n",
      "Action-Suck\n",
      "Need to remove dirt clump at correct location\n",
      "A thing which is not agent, but a dirt clump =  <DirtClump>\n",
      "Location of dirt clod =  (0, 0)\n",
      "Before dirt count update, agent.performance =  2\n",
      "After execute_action, agent.performance =  4\n",
      "---END---\n",
      "---------\n",
      "\n",
      "\n",
      "<---START--->\n",
      "Simulation: step = 3\n",
      "\n",
      "In adxyz_VacuumEnvironment - percept override:\n",
      "Self =  <__main__.adxyz_VacuumEnvironment object at 0x105498128>\n",
      "Self.things =  [<adxyz_SimpleReflexAgentVacuum>]\n",
      "Agent ID =  <adxyz_SimpleReflexAgentVacuum>\n",
      "Agent location =  (0, 0)\n",
      "Agent performance =  4\n",
      "\n",
      "In adxyz_VacuumEnvironment - execute_action override:\n",
      "self =  <__main__.adxyz_VacuumEnvironment object at 0x105498128>\n",
      "agent =  <adxyz_SimpleReflexAgentVacuum>\n",
      "current agent action =  MoveRight\n",
      "\n",
      "Action-MoveRight\n",
      "agent direction before MoveRight =  <agents.Direction object at 0x105498048>\n",
      "agent location before MoveRight =  (0, 0)\n",
      "agent direction after MoveRight =  <agents.Direction object at 0x105498048>\n",
      "agent location after MoveRight =  (1, 0)\n",
      "\n",
      "Before dirt count update, agent.performance =  4\n",
      "After execute_action, agent.performance =  6\n",
      "---END---\n",
      "---------\n",
      "\n",
      "\n",
      "<---START--->\n",
      "Simulation: step = 4\n",
      "\n",
      "In adxyz_VacuumEnvironment - percept override:\n",
      "Self =  <__main__.adxyz_VacuumEnvironment object at 0x105498128>\n",
      "Self.things =  [<adxyz_SimpleReflexAgentVacuum>]\n",
      "Agent ID =  <adxyz_SimpleReflexAgentVacuum>\n",
      "Agent location =  (1, 0)\n",
      "Agent performance =  6\n",
      "\n",
      "In adxyz_VacuumEnvironment - execute_action override:\n",
      "self =  <__main__.adxyz_VacuumEnvironment object at 0x105498128>\n",
      "agent =  <adxyz_SimpleReflexAgentVacuum>\n",
      "current agent action =  MoveLeft\n",
      "\n",
      "Action-MoveLeft\n",
      "agent direction before MoveLeft =  <agents.Direction object at 0x105498048>\n",
      "agent location before MoveLeft =  (1, 0)\n",
      "agent direction after MoveLeft =  <agents.Direction object at 0x10531ffd0>\n",
      "agent location after MoveLeft =  (0, 0)\n",
      "\n",
      "Before dirt count update, agent.performance =  6\n",
      "After execute_action, agent.performance =  8\n",
      "---END---\n",
      "---------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a loop over environments to run simulation\n",
    "\n",
    "# Loop over agent placements\n",
    "##for iSimAgentPlacement in range(len(initAgent)):\n",
    "for iSimAgentPlacement in range(1):\n",
    "    print(\"Simulation: iSimAgentPlacement = \", iSimAgentPlacement)\n",
    "\n",
    "# Loop over dirt placements\n",
    "    for iSimDirtPlacement in range(len(initDirt)):\n",
    "        print (\"Simulation: iSimDirtPlacement = \" , iSimDirtPlacement)\n",
    "        \n",
    "        myVacEnv = adxyz_VacuumEnvironment() #Create a new environment for each dirt/agent setup\n",
    "        myVacEnv.width = 2\n",
    "        myVacEnv.height = 1\n",
    "\n",
    "        for iPlace in range(len(initDirt[iSimDirtPlacement])):\n",
    "            print (\"Simulation: iPlace = \" , iPlace)\n",
    "            currInitDirtLocation = initDirt[iSimDirtPlacement][iPlace]\n",
    "            print(\"Simulation: currInitDirtLocation = \", currInitDirtLocation)\n",
    "            myVacEnv.add_thing(DirtClump(),location=currInitDirtLocation)\n",
    "            \n",
    "#\n",
    "# Now setup the agent.\n",
    "#\n",
    "        myAgent=adxyz_SimpleReflexAgentVacuum()\n",
    "        myAgent.program=SimpleReflexClean  #Place the agent program here\n",
    "        myAgent.performance=0\n",
    "\n",
    "# Instantiate a direction object for 2D generality\n",
    "        myAgent.direction = Direction(\"right\")  # need to leverage heading mechanism\n",
    "        \n",
    "# Add agent to environment\n",
    "        myVacEnv.add_thing(myAgent,location=(1,0))\n",
    "        print()\n",
    "        print(\"Environment:\")\n",
    "        for iThings in myVacEnv.things:\n",
    "            print(iThings, iThings.location)\n",
    "        print()\n",
    "        \n",
    "#\n",
    "# Now step the environment clock\n",
    "#\n",
    "        numSteps = 5\n",
    "        for iStep in range(numSteps):\n",
    "            print()\n",
    "            print(\"<---START--->\")\n",
    "            print(\"Simulation: step =\", iStep)\n",
    "            myVacEnv.step()\n",
    "            print(\"---END---\")\n",
    "            print(\"---------\")\n",
    "            print()\n",
    "    \n",
    "#\n",
    "# End of script\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "- Get scoring correct - use internal values, not hardcoded\n",
    "- Clean up comments/prints\n",
    "- Make processing more generalized\n",
    "-- Introduce multiple dirt clods.\n",
    "-- Introduce multiple agents.\n",
    "-- Add heading sense\n",
    "- Move data to cloud"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
