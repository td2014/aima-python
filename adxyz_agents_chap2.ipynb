{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGENT #\n",
    "\n",
    "An agent, as defined in 2.1 is anything that can perceive its <b>environment</b> through sensors, and act upon that environment through actuators based on its <b>agent program</b>. This can be a dog, robot, or even you. As long as you can perceive the environment and act on it, you are an agent. This notebook will explain how to implement a simple agent, create an environment, and create a program that helps the agent act on the environment based on its percepts.\n",
    "\n",
    "Before moving on, review the </b>Agent</b> and </b>Environment</b> classes in <b>[agents.py](https://github.com/aimacode/aima-python/blob/master/agents.py)</b>.\n",
    "\n",
    "Let's begin by importing all the functions from the agents.py module and creating our first agent - a blind dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from agents import *\n",
    "\n",
    "#class BlindDog(Agent):\n",
    "#    def eat(self, thing):\n",
    "#        print(\"Dog: Ate food at {}.\".format(self.location))\n",
    "#            \n",
    "#    def drink(self, thing):\n",
    "#        print(\"Dog: Drank water at {}.\".format( self.location))\n",
    "#\n",
    "#dog = BlindDog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have just done is create a dog who can only feel what's in his location (since he's blind), and can eat or drink. Let's see if he's alive..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(dog.alive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--- \n",
    "![Cool dog](https://gifgun.files.wordpress.com/2015/07/wpid-wp-1435860392895.gif) This is our dog. How cool is he? Well, he's hungry and needs to go search for food. For him to do this, we need to give him a program. But before that, let's create a park for our dog to play in.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENVIRONMENT #\n",
    "\n",
    "A park is an example of an environment because our dog can perceive and act upon it. The <b>Environment</b> class in agents.py is an abstract class, so we will have to create our own subclass from it before we can use it. The abstract class must contain the following methods:\n",
    "\n",
    "<li><b>percept(self, agent)</b> - returns what the agent perceives</li>\n",
    "<li><b>execute_action(self, agent, action)</b> - changes the state of the environment based on what the agent does.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#class Food(Thing):\n",
    "#    pass\n",
    "\n",
    "#class Water(Thing):\n",
    "#    pass\n",
    "\n",
    "#class Park(Environment):\n",
    "#    def percept(self, agent):\n",
    "#        '''prints & return a list of things that are in our agent's location'''\n",
    "#        things = self.list_things_at(agent.location)\n",
    "#        print(things)\n",
    "#        return things\n",
    "    \n",
    "#    def execute_action(self, agent, action):\n",
    "#        '''changes the state of the environment based on what the agent does.'''\n",
    "#        if action == \"move down\":\n",
    "#            agent.movedown()\n",
    "#        elif action == \"eat\":\n",
    "#            items = self.list_things_at(agent.location, tclass=Food)\n",
    "#            if len(items) != 0:\n",
    "#                if agent.eat(items[0]): #Have the dog pick eat the first item\n",
    "#                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "#        elif action == \"drink\":\n",
    "#            items = self.list_things_at(agent.location, tclass=Water)\n",
    "#            if len(items) != 0:\n",
    "#                if agent.drink(items[0]): #Have the dog drink the first item\n",
    "#                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "                    \n",
    "#    def is_done(self):\n",
    "#        '''By default, we're done when we can't find a live agent, \n",
    "#        but to prevent killing our cute dog, we will or it with when there is no more food or water'''\n",
    "#        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "#        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "#        return dead_agents or no_edibles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wumpus Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from ipythonblocks import BlockGrid\n",
    "#from agents import *\n",
    "\n",
    "#color = {\"Breeze\": (225, 225, 225),\n",
    "#        \"Pit\": (0,0,0),\n",
    "#        \"Gold\": (253, 208, 23),\n",
    "#        \"Glitter\": (253, 208, 23),\n",
    "#        \"Wumpus\": (43, 27, 23),\n",
    "#        \"Stench\": (128, 128, 128),\n",
    "#        \"Explorer\": (0, 0, 255),\n",
    "#        \"Wall\": (44, 53, 57)\n",
    "#        }\n",
    "\n",
    "#def program(percepts):\n",
    "#    '''Returns an action based on it's percepts'''\n",
    "#    print(percepts)\n",
    "#    return input()\n",
    "\n",
    "#w = WumpusEnvironment(program, 7, 7)         \n",
    "#grid = BlockGrid(w.width, w.height, fill=(123, 234, 123))\n",
    "\n",
    "#def draw_grid(world):\n",
    "#    global grid\n",
    "#    grid[:] = (123, 234, 123)\n",
    "#    for x in range(0, len(world)):\n",
    "#        for y in range(0, len(world[x])):\n",
    "#            if len(world[x][y]):\n",
    "#                grid[y, x] = color[world[x][y][-1].__class__.__name__]\n",
    "\n",
    "#def step():\n",
    "#    global grid, w\n",
    "#    draw_grid(w.get_world())\n",
    "#    grid.show()\n",
    "#    w.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'step' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-241028386f35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'step' is not defined"
     ]
    }
   ],
   "source": [
    "step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PROGRAM #\n",
    "Now that we have a <b>Park</b> Class, we need to implement a <b>program</b> module for our dog. A program controls how the dog acts upon it's environment. Our program will be very simple, and is shown in the table below.\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><b>Percept:</b> </td>\n",
    "        <td>Feel Food </td>\n",
    "        <td>Feel Water</td>\n",
    "        <td>Feel Nothing</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "       <td><b>Action:</b> </td>\n",
    "       <td>eat</td>\n",
    "       <td>drink</td>\n",
    "       <td>move up</td>\n",
    "   </tr>\n",
    "        \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#class BlindDog(Agent):\n",
    "#    location = 1\n",
    "    \n",
    "#    def movedown(self):\n",
    "#        self.location += 1\n",
    "        \n",
    "#    def eat(self, thing):\n",
    "#        '''returns True upon success or False otherwise'''\n",
    "#        if isinstance(thing, Food):\n",
    "#            print(\"Dog: Ate food at {}.\".format(self.location))\n",
    "#            return True\n",
    "#        return False\n",
    "    \n",
    "#    def drink(self, thing):\n",
    "#        ''' returns True upon success or False otherwise'''\n",
    "#        if isinstance(thing, Water):\n",
    "#            print(\"Dog: Drank water at {}.\".format(self.location))\n",
    "#            return True\n",
    "#        return False\n",
    "        \n",
    "#def program(percepts):\n",
    "#    '''Returns an action based on it's percepts'''\n",
    "#    for p in percepts:\n",
    "#        if isinstance(p, Food):\n",
    "#            return 'eat'\n",
    "#        elif isinstance(p, Water):\n",
    "#            return 'drink'\n",
    "#    return 'move down'               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#park = Park()\n",
    "#dog = BlindDog(program)\n",
    "#dogfood = Food()\n",
    "#water = Water()\n",
    "#park.add_thing(dog, 0)\n",
    "#park.add_thing(dogfood, 5)\n",
    "#park.add_thing(water, 7)\n",
    "\n",
    "#park.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's how easy it is to implement an agent, its program, and environment. But that was a very simple case. What if our environment was 2-Dimentional instead of 1? And what if we had multiple agents?\n",
    "\n",
    "To make our Park 2D, we will need to make it a subclass of <b>XYEnvironment</b> instead of Environment. Also, let's add a person to play fetch with the dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class Park(XYEnvironment):\n",
    "#    def percept(self, agent):\n",
    "#        '''prints & return a list of things that are in our agent's location'''\n",
    "#        things = self.list_things_at(agent.location)\n",
    "#        print(things)\n",
    "#        return things\n",
    "    \n",
    "#    def execute_action(self, agent, action):\n",
    "#        '''changes the state of the environment based on what the agent does.'''\n",
    "#        if action == \"move down\":\n",
    "#            agent.movedown()\n",
    "#        elif action == \"eat\":\n",
    "#            items = self.list_things_at(agent.location, tclass=Food)\n",
    "#            if len(items) != 0:\n",
    "#                if agent.eat(items[0]): #Have the dog pick eat the first item\n",
    "#                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "#        elif action == \"drink\":\n",
    "#            items = self.list_things_at(agent.location, tclass=Water)\n",
    "#            if len(items) != 0:\n",
    "#                if agent.drink(items[0]): #Have the dog drink the first item\n",
    "#                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "                    \n",
    "#    def is_done(self):\n",
    "#        '''By default, we're done when we can't find a live agent, \n",
    "#        but to prevent killing our cute dog, we will or it with when there is no more food or water'''\n",
    "#        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "#        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "#        return dead_agents or no_edibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.8) Implement a performance-measuring environment simulator for the vacuum-cleaner world depicted in Figure 2.2 and specified on page 38.  Your implementation should be modular so that the sensors, actuators, and enviroment characteristics (size, shape, dirt placement, etc.) can be changed easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agents import *\n",
    "class adxyz_VacuumEnvironment(XYEnvironment):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.9) Implement a simple reflex agent for the vacuum environment in Exercise 2.8.  Run the environment with this agent for all possible initial dirt configurations and agent locations.  Record the performance score for each consideration and the overall average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[(0, 0)]\n",
      "[(0, 1)]\n",
      "[(0, 0), (0, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Define the initial dirt configurations\n",
    "initDirt=[]\n",
    "initDirt.append([])             # neither location dirty\n",
    "initDirt.append([(0,0)])        # square A dirty, square B clean\n",
    "initDirt.append([(0,1)])        # square A clean, square B dirty\n",
    "initDirt.append([(0,0),(0,1)])  # sqaure A dirty, square B dirty\n",
    "\n",
    "print(initDirt[0])\n",
    "print(initDirt[1])\n",
    "print(initDirt[2])\n",
    "print(initDirt[3])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
