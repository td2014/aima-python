{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGENT #\n",
    "\n",
    "An agent, as defined in 2.1 is anything that can perceive its <b>environment</b> through sensors, and act upon that environment through actuators based on its <b>agent program</b>. This can be a dog, robot, or even you. As long as you can perceive the environment and act on it, you are an agent. This notebook will explain how to implement a simple agent, create an environment, and create a program that helps the agent act on the environment based on its percepts.\n",
    "\n",
    "Before moving on, review the </b>Agent</b> and </b>Environment</b> classes in <b>[agents.py](https://github.com/aimacode/aima-python/blob/master/agents.py)</b>.\n",
    "\n",
    "Let's begin by importing all the functions from the agents.py module and creating our first agent - a blind dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from agents import *\n",
    "\n",
    "#class BlindDog(Agent):\n",
    "#    def eat(self, thing):\n",
    "#        print(\"Dog: Ate food at {}.\".format(self.location))\n",
    "#            \n",
    "#    def drink(self, thing):\n",
    "#        print(\"Dog: Drank water at {}.\".format( self.location))\n",
    "#\n",
    "#dog = BlindDog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have just done is create a dog who can only feel what's in his location (since he's blind), and can eat or drink. Let's see if he's alive..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(dog.alive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--- \n",
    "![Cool dog](https://gifgun.files.wordpress.com/2015/07/wpid-wp-1435860392895.gif) This is our dog. How cool is he? Well, he's hungry and needs to go search for food. For him to do this, we need to give him a program. But before that, let's create a park for our dog to play in.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENVIRONMENT #\n",
    "\n",
    "A park is an example of an environment because our dog can perceive and act upon it. The <b>Environment</b> class in agents.py is an abstract class, so we will have to create our own subclass from it before we can use it. The abstract class must contain the following methods:\n",
    "\n",
    "<li><b>percept(self, agent)</b> - returns what the agent perceives</li>\n",
    "<li><b>execute_action(self, agent, action)</b> - changes the state of the environment based on what the agent does.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#class Food(Thing):\n",
    "#    pass\n",
    "\n",
    "#class Water(Thing):\n",
    "#    pass\n",
    "\n",
    "#class Park(Environment):\n",
    "#    def percept(self, agent):\n",
    "#        '''prints & return a list of things that are in our agent's location'''\n",
    "#        things = self.list_things_at(agent.location)\n",
    "#        print(things)\n",
    "#        return things\n",
    "    \n",
    "#    def execute_action(self, agent, action):\n",
    "#        '''changes the state of the environment based on what the agent does.'''\n",
    "#        if action == \"move down\":\n",
    "#            agent.movedown()\n",
    "#        elif action == \"eat\":\n",
    "#            items = self.list_things_at(agent.location, tclass=Food)\n",
    "#            if len(items) != 0:\n",
    "#                if agent.eat(items[0]): #Have the dog pick eat the first item\n",
    "#                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "#        elif action == \"drink\":\n",
    "#            items = self.list_things_at(agent.location, tclass=Water)\n",
    "#            if len(items) != 0:\n",
    "#                if agent.drink(items[0]): #Have the dog drink the first item\n",
    "#                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "                    \n",
    "#    def is_done(self):\n",
    "#        '''By default, we're done when we can't find a live agent, \n",
    "#        but to prevent killing our cute dog, we will or it with when there is no more food or water'''\n",
    "#        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "#        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "#        return dead_agents or no_edibles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wumpus Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from ipythonblocks import BlockGrid\n",
    "#from agents import *\n",
    "\n",
    "#color = {\"Breeze\": (225, 225, 225),\n",
    "#        \"Pit\": (0,0,0),\n",
    "#        \"Gold\": (253, 208, 23),\n",
    "#        \"Glitter\": (253, 208, 23),\n",
    "#        \"Wumpus\": (43, 27, 23),\n",
    "#        \"Stench\": (128, 128, 128),\n",
    "#        \"Explorer\": (0, 0, 255),\n",
    "#        \"Wall\": (44, 53, 57)\n",
    "#        }\n",
    "\n",
    "#def program(percepts):\n",
    "#    '''Returns an action based on it's percepts'''\n",
    "#    print(percepts)\n",
    "#    return input()\n",
    "\n",
    "#w = WumpusEnvironment(program, 7, 7)         \n",
    "#grid = BlockGrid(w.width, w.height, fill=(123, 234, 123))\n",
    "\n",
    "#def draw_grid(world):\n",
    "#    global grid\n",
    "#    grid[:] = (123, 234, 123)\n",
    "#    for x in range(0, len(world)):\n",
    "#        for y in range(0, len(world[x])):\n",
    "#            if len(world[x][y]):\n",
    "#                grid[y, x] = color[world[x][y][-1].__class__.__name__]\n",
    "\n",
    "#def step():\n",
    "#    global grid, w\n",
    "#    draw_grid(w.get_world())\n",
    "#    grid.show()\n",
    "#    w.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PROGRAM #\n",
    "Now that we have a <b>Park</b> Class, we need to implement a <b>program</b> module for our dog. A program controls how the dog acts upon it's environment. Our program will be very simple, and is shown in the table below.\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><b>Percept:</b> </td>\n",
    "        <td>Feel Food </td>\n",
    "        <td>Feel Water</td>\n",
    "        <td>Feel Nothing</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "       <td><b>Action:</b> </td>\n",
    "       <td>eat</td>\n",
    "       <td>drink</td>\n",
    "       <td>move up</td>\n",
    "   </tr>\n",
    "        \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#class BlindDog(Agent):\n",
    "#    location = 1\n",
    "    \n",
    "#    def movedown(self):\n",
    "#        self.location += 1\n",
    "        \n",
    "#    def eat(self, thing):\n",
    "#        '''returns True upon success or False otherwise'''\n",
    "#        if isinstance(thing, Food):\n",
    "#            print(\"Dog: Ate food at {}.\".format(self.location))\n",
    "#            return True\n",
    "#        return False\n",
    "    \n",
    "#    def drink(self, thing):\n",
    "#        ''' returns True upon success or False otherwise'''\n",
    "#        if isinstance(thing, Water):\n",
    "#            print(\"Dog: Drank water at {}.\".format(self.location))\n",
    "#            return True\n",
    "#        return False\n",
    "        \n",
    "#def program(percepts):\n",
    "#    '''Returns an action based on it's percepts'''\n",
    "#    for p in percepts:\n",
    "#        if isinstance(p, Food):\n",
    "#            return 'eat'\n",
    "#        elif isinstance(p, Water):\n",
    "#            return 'drink'\n",
    "#    return 'move down'               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#park = Park()\n",
    "#dog = BlindDog(program)\n",
    "#dogfood = Food()\n",
    "#water = Water()\n",
    "#park.add_thing(dog, 0)\n",
    "#park.add_thing(dogfood, 5)\n",
    "#park.add_thing(water, 7)\n",
    "\n",
    "#park.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's how easy it is to implement an agent, its program, and environment. But that was a very simple case. What if our environment was 2-Dimentional instead of 1? And what if we had multiple agents?\n",
    "\n",
    "To make our Park 2D, we will need to make it a subclass of <b>XYEnvironment</b> instead of Environment. Also, let's add a person to play fetch with the dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class Park(XYEnvironment):\n",
    "#    def percept(self, agent):\n",
    "#        '''prints & return a list of things that are in our agent's location'''\n",
    "#        things = self.list_things_at(agent.location)\n",
    "#        print(things)\n",
    "#        return things\n",
    "    \n",
    "#    def execute_action(self, agent, action):\n",
    "#        '''changes the state of the environment based on what the agent does.'''\n",
    "#        if action == \"move down\":\n",
    "#            agent.movedown()\n",
    "#        elif action == \"eat\":\n",
    "#            items = self.list_things_at(agent.location, tclass=Food)\n",
    "#            if len(items) != 0:\n",
    "#                if agent.eat(items[0]): #Have the dog pick eat the first item\n",
    "#                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "#        elif action == \"drink\":\n",
    "#            items = self.list_things_at(agent.location, tclass=Water)\n",
    "#            if len(items) != 0:\n",
    "#                if agent.drink(items[0]): #Have the dog drink the first item\n",
    "#                    self.delete_thing(items[0]) #Delete it from the Park after.\n",
    "                    \n",
    "#    def is_done(self):\n",
    "#        '''By default, we're done when we can't find a live agent, \n",
    "#        but to prevent killing our cute dog, we will or it with when there is no more food or water'''\n",
    "#        no_edibles = not any(isinstance(thing, Food) or isinstance(thing, Water) for thing in self.things)\n",
    "#        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "#        return dead_agents or no_edibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7)  Write pseudocode for the goal-based and utility based agents:\n",
    "\n",
    "** Goal-based: **\n",
    "\n",
    "    currentDeltaAction=0\n",
    "    currentBestAction=[]\n",
    "    While goal==false:\n",
    "        for iAction in listOfActions:\n",
    "            if deltaValue(iAction)>currentDeltaAction:\n",
    "                currentBestAction=iAction\n",
    "        agent_action(currentBestAction):\n",
    "    \n",
    "\n",
    "** Utility-based: **\n",
    "\n",
    "    currentDeltaUtility=0\n",
    "    currentBestAction=[]\n",
    "    While true:\n",
    "        if iAction in listOfActions:\n",
    "            if deltaUtility(iAction)>currentBestUtility:\n",
    "                currentBestAction=iAction\n",
    "            \n",
    "        agent_action(currentBestAction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.8) Implement a performance-measuring environment simulator for the vacuum-cleaner world depicted in Figure 2.2 and specified on page 38.  Your implementation should be modular so that the sensors, actuators, and enviroment characteristics (size, shape, dirt placement, etc.) can be changed easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent Name:  Vacuum Robot Agent\n",
    "-------------------------------\n",
    "*Performance Measure:*  +1 point for each clean square at each time step, for 1000 time steps\n",
    "\n",
    "*Environment:*  Two squares at positions (0,0) and (1,0).  The squares can either be dirty or clean.  The agent cannot go outside those two positions.\n",
    "\n",
    "*Actuators:*  The actuators for the agent consist of the ability to move between the squares and the ability to suck up dirt.\n",
    "\n",
    "*Sensors:*  The sensors allow for the agent to know current location and also whether there is dirt or not at the square the currently occupy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agents import *\n",
    "\n",
    "# Define the dirt clump class\n",
    "class DirtClump(Thing):\n",
    "    pass\n",
    "\n",
    "#Define the environment class\n",
    "class adxyz_VacuumEnvironment(XYEnvironment):\n",
    "\n",
    "# Need to override the percept method \n",
    "    def percept(self, agent):\n",
    "        print ()\n",
    "        print (\"In adxyz_VacuumEnvironment - percept override:\")\n",
    "        print (\"Self = \", self)\n",
    "        print (\"Self.things = \", self.things)\n",
    "        print (\"Agent ID = \", agent)\n",
    "        print (\"Agent location = \", agent.location)\n",
    "        print (\"Agent performance = \", agent.performance)\n",
    "        \n",
    "        for iThing in self.things:\n",
    "            if iThing.location==agent.location:  #check location\n",
    "                if iThing != agent:  # Don't return agent information\n",
    "                    if (isinstance(iThing, DirtClump)):\n",
    "                        print (\"A thing which is not agent, but a dirt clump = \", iThing )\n",
    "                        print (\"Location = \", iThing.location)\n",
    "                        return agent.location, \"DirtClump\"\n",
    "                    \n",
    "        return agent.location, \"CleanSquare\"  #Default, if we don't find a dirt clump.\n",
    "                \n",
    "# Need to override the action method (and update performance measure.)\n",
    "    def execute_action(self, agent, action):\n",
    "        print ()\n",
    "        print (\"In adxyz_VacuumEnvironment - execute_action override:\")\n",
    "        print(\"self = \", self)\n",
    "        print(\"agent = \", agent)\n",
    "        print(\"current agent action = \", action)\n",
    "        print()\n",
    "        if action==\"Suck\":\n",
    "            print(\"Action-Suck\")\n",
    "            print(\"Need to remove dirt clump at correct location\")\n",
    "            deleteList = []\n",
    "            for iThing in self.things:\n",
    "                if iThing.location==agent.location:  #check location\n",
    "                    if (isinstance(iThing, DirtClump)):  # Only suck dirt\n",
    "                        print (\"A thing which is not agent, but a dirt clump = \", iThing)\n",
    "                        print (\"Location of dirt clod = \", iThing.location)\n",
    "                        self.delete_thing(iThing)\n",
    "                        break  # can only do one deletion per action.\n",
    "                                   \n",
    "        elif action==\"MoveRight\":\n",
    "            print(\"Action-MoveRight\")\n",
    "            print(\"agent direction before MoveRight = \", agent.direction)\n",
    "            print(\"agent location before MoveRight = \", agent.location)\n",
    "            agent.bump = False\n",
    "            agent.direction.direction = \"right\"\n",
    "            agent.bump = self.move_to(agent, agent.direction.move_forward(agent.location))\n",
    "            print(\"agent direction after MoveRight = \", agent.direction)\n",
    "            print(\"agent location after MoveRight = \", agent.location)\n",
    "            print()\n",
    "            \n",
    "        elif action==\"MoveLeft\":\n",
    "            print(\"Action-MoveLeft\")\n",
    "            print(\"agent direction before MoveLeft = \", agent.direction)\n",
    "            print(\"agent location before MoveLeft = \", agent.location)\n",
    "            agent.bump = False\n",
    "            agent.direction.direction = \"left\"\n",
    "            agent.bump = self.move_to(agent, agent.direction.move_forward(agent.location))\n",
    "            print(\"agent direction after MoveLeft = \", agent.direction)\n",
    "            print(\"agent location after MoveLeft = \", agent.location)\n",
    "            print()\n",
    "            \n",
    "        elif action==\"DoNothing\":\n",
    "            print(\"Action-DoNothing\")\n",
    "            \n",
    "        else:\n",
    "            print(\"Action-Not Understood\")  #probably error.  Don't go to score section.\n",
    "            return\n",
    "                \n",
    "###\n",
    "### Count up number of clean squares (indirectly)\n",
    "### and add that to the agent peformance score\n",
    "###\n",
    "\n",
    "        print(\"Before dirt count update, agent.performance = \", agent.performance)\n",
    "        dirtCount=0\n",
    "        for iThing in self.things:\n",
    "            if isinstance(iThing, DirtClump):\n",
    "                dirtCount = dirtCount+1\n",
    "\n",
    "        cleanSquareCount = self.width*self.height-dirtCount \n",
    "        agent.performance=agent.performance + cleanSquareCount\n",
    "        print(\"After execute_action, agent.performance = \", agent.performance)\n",
    "        return    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.9) Implement a simple reflex agent for the vacuum environment in Exercise 2.8.  Run the environment with this agent for all possible initial dirt configurations and agent locations.  Record the performance score for each consideration and the overall average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# The program for the simple reflex agent is:\n",
    "# \n",
    "# Percept:         Action:\n",
    "# --------         -------\n",
    "# [(0,0),Clean] -> Right\n",
    "# [(0,0),Dirty] -> Suck\n",
    "# [(1,0),Clean] -> Left\n",
    "# [(1,0),Dirty] -> Suck\n",
    "#\n",
    "\n",
    "def adxyz_SimpleReflexVacuum(percept):\n",
    "     \n",
    "    if percept[0] == (0,0) and percept[1]==\"DirtClump\":\n",
    "        return \"Suck\"\n",
    "    elif percept[0] == (1,0) and percept[1]==\"DirtClump\":\n",
    "        return \"Suck\"\n",
    "    elif percept[0] == (0,0) and percept[1]==\"CleanSquare\":\n",
    "        return \"MoveRight\"\n",
    "    elif percept[0] == (1,0) and percept[1]==\"CleanSquare\":\n",
    "        return \"MoveLeft\"\n",
    "    else:\n",
    "        return \"DoNothing\" # Not sure how you would get here, but DoNothing to be safe.\n",
    "\n",
    "# Instantiate a simple reflex vacuum agent\n",
    "class adxyz_SimpleReflexVacuumAgent(Agent):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the initial dirt configurations\n",
    "initDirt=[]\n",
    "initDirt.append([])             # neither location dirty - format(X,Y)-locations:A=(0,0), B=(1,0)\n",
    "###initDirt.append([(0,0)])        # square A dirty, square B clean\n",
    "##initDirt.append([(1,0)])        # square A clean, square B dirty\n",
    "###initDirt.append([(0,0),(1,0)])  # square A dirty, square B dirty\n",
    "\n",
    "print(\"initDirt = \", initDirt)\n",
    "\n",
    "#\n",
    "# Create agent placements\n",
    "#\n",
    "initAgent=[]\n",
    "initAgent.append((0,0))\n",
    "initAgent.append((1,0))\n",
    "print(\"initAgent = \", initAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a loop over environments to run simulation\n",
    "\n",
    "# Loop over agent placements\n",
    "for iSimAgentPlacement in range(len(initAgent)):\n",
    "###for iSimAgentPlacement in range(1):\n",
    "    print(\"Simulation: iSimAgentPlacement = \", iSimAgentPlacement)\n",
    "\n",
    "# Loop over dirt placements\n",
    "    for iSimDirtPlacement in range(len(initDirt)):\n",
    "        print (\"Simulation: iSimDirtPlacement = \" , iSimDirtPlacement)\n",
    "        myVacEnv = adxyz_VacuumEnvironment() #Create a new environment for each dirt/agent setup\n",
    "        myVacEnv.width = 2\n",
    "        myVacEnv.height = 1\n",
    "\n",
    "        for iPlace in range(len(initDirt[iSimDirtPlacement])):\n",
    "            print (\"Simulation: iPlace = \" , iPlace)\n",
    "            myVacEnv.add_thing(DirtClump(),location=initDirt[iSimDirtPlacement][iPlace])\n",
    "            \n",
    "#\n",
    "# Now setup the agent.\n",
    "#\n",
    "        myAgent=adxyz_SimpleReflexVacuumAgent()\n",
    "        myAgent.program=adxyz_SimpleReflexVacuum  #Place the agent program here\n",
    "        myAgent.performance=0\n",
    "\n",
    "# Instantiate a direction object for 2D generality\n",
    "        myAgent.direction = Direction(\"up\")  # need to leverage heading mechanism\n",
    "        \n",
    "# Add agent to environment\n",
    "        myVacEnv.add_thing(myAgent,location=initAgent[iSimAgentPlacement])\n",
    "        print()\n",
    "        print(\"Environment:\")\n",
    "        for iThings in myVacEnv.things:\n",
    "            print(iThings, iThings.location)\n",
    "        print()\n",
    "        \n",
    "#\n",
    "# Now step the environment clock\n",
    "#\n",
    "        numSteps = 5\n",
    "        for iStep in range(numSteps):\n",
    "            print()\n",
    "            print(\"<-START->\")\n",
    "            print(\"Simulation: step =\", iStep)\n",
    "            myVacEnv.step()\n",
    "            print(\"---END---\")\n",
    "            print(\"---------\")\n",
    "            print()\n",
    "            \n",
    "        print()    \n",
    "        print(\"<====>\")\n",
    "        print(\"<====>\")\n",
    "        #need to keep running tally of initial configuration and final performance\n",
    "        print(\"Final performance measure for Agent = \", myAgent.performance)\n",
    "        print(\"======\")\n",
    "        print(\"======\")\n",
    "        print()\n",
    "#\n",
    "# End of script\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "- Clean up comments/prints (mostly done)\n",
    "- Make processing more generalized\n",
    "-- Introduce multiple dirt clods.\n",
    "-- Introduce multiple agents.\n",
    "- Move data to cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.10) Consider the modified version of the performance metric where the agent is penalized on point for each movement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Can a simple reflex agent be perfectly rational for this environment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, there are 8 cases to consider (8 states of the environment):  4 initial dirt configurations and 2 initial agent configurations.\n",
    "\n",
    "Case 1a) Clean A, Clean B, agent in square A: The maximum performance score would be 2 points awarded at each step, because there are two clean squares.  If we were to design a reflex agent, we could use the following program:  [(clean, squareA)-->DoNothing]\n",
    "Case 1b) Clean A, Clean B, agent in square B: The maximum performance score would be 2 points awarded at each step, because there are two clean squares.  If we were to design a reflex agent, we could use the following program: [(clean, SquareB)-->DoNothing]\n",
    "\n",
    "Case 2a) Dirt A, Clean B, agent in square A:  The maximum performance score would be 2 points, once the dirt is removed from square A.  The agent program that could accomplish this is:  [(dirt, squareA)-->suck], [(clean, squareA)-->DoNothing]\n",
    "Case 2b) Dirt A, Clean B, agent in square B:  The maximum performance score would be 1-1 (1 point for clean B, -1 for move to A), then 2 points for each step after that.  The agent program that could accomplish this is: [(clean, squareB)-->MoveLeft], [(dirt, squareA)-->suck], [(clean, squareA)-->DoNothing].  However, this is in conflict with the optimum program for Case 1b.\n",
    "\n",
    "Case 3a) Clean A, Dirt B, agent in squareA:  The maximum peformance score would be 1(for clean initial square) -1 (for move to B) = 0 points for step 1.  2 points each step from then on.  The agent program that could accomplish this would be:  [(clean, squareA)-->MoveRight], [(Dirt, SquareB)-->Suck], [(clean,SquareB)-->doNothing].  However, we can see from this situation that our program for 3a is in conflict with the program for 1a.\n",
    "Case 3b) Clean A, Dirt B, agent in squareB:  The maximum performance score for this would be 2 per time step:  The following agent program could accomplish this [(Dirt, SquareB)-->Suck][(clean,SquareB)-->doNothing.\n",
    "\n",
    "Case 4a) Dirt A, Dirt B, Agent in Square A:  The maximum possible performance points would be 1 for first step, 1-1 for second step, 2 points from that step onwards.  An agent function that could accomplish this is:  [(dirt,squareA)-->suck], [(clean,squareA)-->moveRight], [(dirt,SquareB)-->suck], [(clean,SquareB)-->doNothing].  However, this includes an instruction which is in conflict with the optimum program in case 1a.\n",
    "\n",
    "Case 4b) Dirt A, Dirt B, Agent in Square B:  The maximum possible performance points would be 1 for the first step, 1-1 for the second step, and 2 points from the step onwards.  An agent function that could accomplish this is:  [(dirt, squareB)-->suck], [(clean,squareB)-->moveLeft], [(dirt,squareA)-->suck], [(clean, squareA)-->doNothing].  This has instruction which are in conflict with case 1b.  \n",
    "\n",
    "Because we have conflicting instructions in order to achieve optimum performance results, we would have to choose one or the other, which would lead to a suboptimal result in at least one case.  Thus a perfectly rational agent cannot be designed.  By perfectly rational, I mean one that is optimum in every case, since we must assume all cases are possible to occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) What about a reflex agent with state?  Design such an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# The program for the simple reflex agent with state is:\n",
    "# \n",
    "# Percept:         Action:\n",
    "# --------         -------\n",
    "# [(0,0),Clean] -> Right\n",
    "# [(0,0),Dirty] -> Suck\n",
    "# [(1,0),Clean] -> Left\n",
    "# [(1,0),Dirty] -> Suck\n",
    "#\n",
    "\n",
    "def adxyz_SimpleReflexStateVacuum(percept):\n",
    "     \n",
    "    if percept[0] == (0,0) and percept[1]==\"DirtClump\":\n",
    "        return \"Suck\"\n",
    "    elif percept[0] == (1,0) and percept[1]==\"DirtClump\":\n",
    "        return \"Suck\"\n",
    "    elif percept[0] == (0,0) and percept[1]==\"CleanSquare\":\n",
    "        return \"MoveRight\"\n",
    "    elif percept[0] == (1,0) and percept[1]==\"CleanSquare\":\n",
    "        return \"MoveLeft\"\n",
    "    else:\n",
    "        return \"DoNothing\" # Not sure how you would get here, but DoNothing to be safe.\n",
    "\n",
    "# Instantiate a simple reflex vacuum agent\n",
    "class adxyz_SimpleReflexStateVacuumAgent(Agent):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking to design agents that can solve goal seeking problems.\n",
    "Step 1:  Define the goal, which is a state of the environment.  For example, the desired goal might be \"Car in Bucharest\" or \"Robot in square (10,10) with all squares clean\"  \n",
    "Step 2:  Define the problem.  \n",
    "- Define the states of the environment (atomic)\n",
    "- Define the initial state\n",
    "- Define legal actions\n",
    "- Define transitions\n",
    "- Define goal test\n",
    "- Define path/step costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graph-search:  A key algorithm for expanding the search space, that avoids redundent paths.  The search methods in this chapter are based on graph-search algorithm.\n",
    "Each step of the algorithm does this:\n",
    "Unexplored state -> frontier states -> explored states.\n",
    "A state can only be in one of the three above categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infrastructure for search algorithms:\n",
    "Graphs - nodes that include references to \n",
    "parent nodes\n",
    "state descriptions\n",
    "action that got from parent to child node\n",
    "path cost (from initial state).\n",
    "\n",
    "Types of cost:\n",
    "Search cost (time to determine solution)\n",
    "Path cost (cost of actual solution - for example distance on a roadmap)\n",
    "Total cost:  Sum of search + path cost (with appropriate scaling to put them in common units)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Search Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm evaluation criteria:\n",
    "- Completeness (Does the algorithm find a solution - or all solutions)\n",
    "- Optimality (Does the algorithm find the best solution)\n",
    "- Time complexity (how long does the algorithm take to find solution)\n",
    "- Space complexity (how much memory is used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uninformed search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This includes all search algorithms that have no idea whether one choice is \"more promising\" than another non-goal state.  These algorithms generate non-goal states and test for goal states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Breadth-first search:  Each node is expanded into the successor nodes one level at a time.  Uses a FIFO queue for the frontier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo-code for BFS search:\n",
    "\n",
    "    unexploredNodes = dict()\n",
    "    exploredNodes = dict()\n",
    "    frontierNodes = initialState\n",
    "    goalNodeFound = False\n",
    "    \n",
    "    while not frontierNodes.empty:\n",
    "        currentNode = frontierNodes.pop\n",
    "        if currentNode.goal == True:\n",
    "            currentNode.pathCost=currentNode.parent.pathCost+currentNode.stepCost\n",
    "            goalNodeFound=True\n",
    "            break\n",
    "        else:\n",
    "            exploredNodes[currentNode]=True   # add current node to explored nodes\n",
    "            for childNode,dummy in currentNode.links.items():  #Any link is a \"child\"\n",
    "                if (childNode in exploredNodes) or (childNode in frontierNodes):\n",
    "                    continue\n",
    "                else:\n",
    "                    frontierNodes.push(childNode)\n",
    "                    childNode.stepCost=childNode.link[currentNode]  # provide step cost\n",
    "                    childNode.parent=currentNode\n",
    "                    del unexploredNodes[childNode]\n",
    "                \n",
    "    If goalNodeFound != True:  # goal node was not set\n",
    "        error\n",
    "        \n",
    "Need to start at goal node and work back to initial state to provide solution pathway:\n",
    "\n",
    "    pathSequence = queue.LifoQueue()\n",
    "\n",
    "    currentNode = goalNode\n",
    "    pathSequence.put(currentNode)\n",
    "\n",
    "    while currentNode != currentNode.parent:\n",
    "        pathSequence.put(currentNode.parent)\n",
    "        currentNode=currentNode.parent\n",
    "\n",
    "    pathSequence.put(currentNode)\n",
    "\n",
    "    while not pathSequence.empty():\n",
    "        print(\"Path sequence = \", pathSequence.get())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a generic graph that could be undirected in general and search it using BFS and a FIFO frontier queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GraphNode():\n",
    "    def __init__(self, initName):\n",
    "        self.links=dict()        # (name of link:step cost)\n",
    "        self.parent=None         # Is assigned during BFS\n",
    "        self.goal=False          # True if goal state\n",
    "        self.pathCost=0\n",
    "        self.stepCost=0\n",
    "        self.frontier=False      # True if node has been added to frontier\n",
    "        self.name=initName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NodeSetup:\n",
      "Node1 =  <__main__.GraphNode object at 0x103ba8fd0>\n",
      "Node2 =  <__main__.GraphNode object at 0x103ba8f98>\n",
      "Node3 =  <__main__.GraphNode object at 0x103bc90b8>\n",
      "Node4 =  <__main__.GraphNode object at 0x103bc90f0>\n",
      "Node5 =  <__main__.GraphNode object at 0x103bc9128>\n",
      "Node6 =  <__main__.GraphNode object at 0x103bc9160>\n",
      "Node1 links =  {<__main__.GraphNode object at 0x103ba8f98>: 10, <__main__.GraphNode object at 0x103bc90b8>: 15}\n",
      "Node2 links =  {<__main__.GraphNode object at 0x103bc9128>: 6, <__main__.GraphNode object at 0x103bc90b8>: 28, <__main__.GraphNode object at 0x103ba8fd0>: 10, <__main__.GraphNode object at 0x103bc9160>: 7}\n",
      "Node3 links =  {<__main__.GraphNode object at 0x103ba8f98>: 28, <__main__.GraphNode object at 0x103bc9128>: 8, <__main__.GraphNode object at 0x103ba8fd0>: 15, <__main__.GraphNode object at 0x103bc90f0>: 17}\n",
      "Node4 links =  {<__main__.GraphNode object at 0x103bc90b8>: 17}\n",
      "Node5 links =  {<__main__.GraphNode object at 0x103ba8f98>: 6, <__main__.GraphNode object at 0x103bc90b8>: 8}\n",
      "Node6 links =  {<__main__.GraphNode object at 0x103ba8f98>: 7}\n",
      "Node6.goal =  True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# create map\n",
    "#\n",
    "#\n",
    "#   Node1 ----- 10 ----- Node2 ---7--- Node6\n",
    "#     |      28--------/ |\n",
    "#     |     /           6\n",
    "#     |    /            |\n",
    "#     15  /          Node5\n",
    "#     |  |             |\n",
    "#     | | =======8======= \n",
    "#     |/ |\n",
    "#   Node3 \n",
    "#     |\n",
    "#     |\n",
    "#     |\n",
    "#     17\n",
    "#     |\n",
    "#     |\n",
    "#     |\n",
    "#   Node4\n",
    "#\n",
    "#\n",
    "Node1=GraphNode(\"Node1\")\n",
    "Node2=GraphNode(\"Node2\")\n",
    "Node3=GraphNode(\"Node3\")\n",
    "Node4=GraphNode(\"Node4\")\n",
    "Node5=GraphNode(\"Node5\")\n",
    "Node6=GraphNode(\"Node6\")\n",
    "\n",
    "Node1.links[Node2]=10\n",
    "Node1.links[Node3]=15\n",
    "\n",
    "Node2.links[Node1]=10\n",
    "Node2.links[Node3]=28\n",
    "Node2.links[Node5]=6\n",
    "Node2.links[Node6]=7\n",
    "\n",
    "Node3.links[Node1]=15\n",
    "Node3.links[Node2]=28\n",
    "Node3.links[Node4]=17\n",
    "Node3.links[Node5]=8\n",
    "\n",
    "Node4.links[Node3]=17\n",
    "\n",
    "Node5.links[Node2]=6\n",
    "Node5.links[Node3]=8\n",
    "\n",
    "Node6.links[Node2]=7\n",
    "\n",
    "print(\"NodeSetup:\")\n",
    "print(\"Node1 = \", Node1)\n",
    "print(\"Node2 = \", Node2)\n",
    "print(\"Node3 = \", Node3)\n",
    "print(\"Node4 = \", Node4)\n",
    "print(\"Node5 = \", Node5)\n",
    "print(\"Node6 = \", Node6)\n",
    "\n",
    "print(\"Node1 links = \", Node1.links)\n",
    "print(\"Node2 links = \", Node2.links)\n",
    "print(\"Node3 links = \", Node3.links)\n",
    "print(\"Node4 links = \", Node4.links)\n",
    "print(\"Node5 links = \", Node5.links)\n",
    "print(\"Node6 links = \", Node6.links)\n",
    "\n",
    "Node1.parent=Node1  # node1 is the initial node - pointing to itself as parent is the flag.\n",
    "\n",
    "Node6.goal=True\n",
    "print(\"Node6.goal = \", Node6.goal)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring frontier nodes:\n",
      "Expanding current node:  Node1\n",
      "Child Node is being added to frontier:  Node2\n",
      "Child Node is being added to frontier:  Node3\n",
      "End of frontier loop:\n",
      "-------\n",
      "\n",
      "Exploring frontier nodes:\n",
      "Expanding current node:  Node2\n",
      "Child Node is being added to frontier:  Node5\n",
      "Child Node has been seen before:  Node3\n",
      "Child Node has been seen before:  Node1\n",
      "Child Node is being added to frontier:  Node6\n",
      "End of frontier loop:\n",
      "-------\n",
      "\n",
      "Exploring frontier nodes:\n",
      "Expanding current node:  Node3\n",
      "Child Node has been seen before:  Node2\n",
      "Child Node has been seen before:  Node5\n",
      "Child Node has been seen before:  Node1\n",
      "Child Node is being added to frontier:  Node4\n",
      "End of frontier loop:\n",
      "-------\n",
      "\n",
      "Exploring frontier nodes:\n",
      "Expanding current node:  Node5\n",
      "Child Node has been seen before:  Node2\n",
      "Child Node has been seen before:  Node3\n",
      "End of frontier loop:\n",
      "-------\n",
      "\n",
      "Exploring frontier nodes:\n",
      "Goal node found.\n",
      "Current Node =  Node6\n",
      "Current Node Parent =  Node2\n",
      "Current Node Step Cost =  7\n",
      "Current Node Path Cost =  17\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Run the BFS process\n",
    "#\n",
    "\n",
    "import queue\n",
    "\n",
    "###exploredNodes = dict()\n",
    "frontierNodes = queue.Queue()\n",
    "goalNodeFound = False\n",
    "\n",
    "#\n",
    "# Initialize the frontier queue\n",
    "#\n",
    "\n",
    "frontierNodes.put(Node1)\n",
    "Node1.frontier=True\n",
    "\n",
    "# Main loop\n",
    "\n",
    "while not frontierNodes.empty():\n",
    "    print(\"Exploring frontier nodes: \")\n",
    "    currentNode = frontierNodes.get()\n",
    "    if currentNode.goal == True:\n",
    "        goalNodeFound=True\n",
    "        break\n",
    "    else:   \n",
    "        print(\"Expanding current node: \", currentNode.name)\n",
    "        for childNode,dummy in currentNode.links.items():  #Any link is a potential \"child\" \n",
    "            if (childNode.frontier==True):\n",
    "                print(\"Child Node has been seen before: \", childNode.name)\n",
    "                continue\n",
    "            else:\n",
    "                print(\"Child Node is being added to frontier: \", childNode.name)\n",
    "                frontierNodes.put(childNode)\n",
    "                childNode.frontier=True\n",
    "                childNode.parent=currentNode\n",
    "                childNode.stepCost=childNode.links[currentNode]  # provide step cost\n",
    "                childNode.pathCost=currentNode.pathCost+childNode.stepCost\n",
    "    \n",
    "    print(\"End of frontier loop:\")\n",
    "    print(\"-------\")\n",
    "    print()\n",
    "                \n",
    "if goalNodeFound != True:  # goal node was not set\n",
    "    print (\"Goal node not found.\")\n",
    "else:\n",
    "    print (\"Goal node found.\")\n",
    "    print (\"Current Node = \", currentNode.name)\n",
    "    print (\"Current Node Parent = \", currentNode.parent.name)\n",
    "    print (\"Current Node Step Cost = \", currentNode.stepCost)\n",
    "    print (\"Current Node Path Cost = \", currentNode.pathCost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path sequence =  Node1\n",
      "Path sequence =  Node2\n",
      "Path sequence =  Node6\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Report out the solution path working backwords from the goal node to the\n",
    "# initial node (which is flagged by having the parent=node)\n",
    "#\n",
    "\n",
    "pathSequence = queue.LifoQueue()\n",
    "pathSequence.put(currentNode)\n",
    "\n",
    "while currentNode != currentNode.parent:\n",
    "    pathSequence.put(currentNode.parent)\n",
    "    currentNode=currentNode.parent\n",
    "\n",
    "# Add the final node, which is the initial in this case\n",
    "# The initial node was specially marked to point to itself as parent\n",
    "\n",
    "while not pathSequence.empty():\n",
    "    print(\"Path sequence = \", pathSequence.get().name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informed search (heuristics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These approaches for searching the graph tend to produce faster results, but are dependent on information that may or may not be available at all times."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
